{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "...................................\n",
      "\n",
      "一共有14776615条出行数据\n",
      "\n",
      "出租车运行的平均时间为：683.4235930894863s\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "import operator\n",
    "import datetime\n",
    "\n",
    "sc = pyspark.SparkContext(\"local\", \"TaxiNY\")\n",
    "# sc = pyspark.SparkContext.getOrCreate(\"local\", \"TaxiNY\")\n",
    "\n",
    "csvFile1 = sc.textFile(\"../dataset/trip_data_1.csv\")\n",
    "\n",
    "header = csvFile1.first()\n",
    "print(\"\\n...................................\\n\")\n",
    "# print(header)\n",
    "\n",
    "# Remove the header\n",
    "csvFile1 = csvFile1.filter(lambda row: row != header)\n",
    "\n",
    "# print(csvFile1.first())\n",
    "\n",
    "csvData = csvFile1.map(lambda lines: lines.split(\",\"))\n",
    "csvData.cache()\n",
    "\n",
    "dataLength = csvData.count()\n",
    "print(f\"一共有{dataLength}条出行数据\\n\")\n",
    "\n",
    "passengerCountRDD = csvData.map(lambda lines: (lines[7], 1))\n",
    "passengerCount = passengerCountRDD.reduceByKey(operator.add).collect()\n",
    "\n",
    "# print(sorted(passengerCount))\n",
    "\n",
    "allPassengerCount = 0\n",
    "for i in sorted(passengerCount):\n",
    "    allPassengerCount += int(i[0]) * int(i[1])\n",
    "\n",
    "# 乘客人数相关\n",
    "countString = \"人数 次数\\n\"\n",
    "with open(\"./file/passengerCount.txt\", \"w\") as f:\n",
    "    for i in sorted(passengerCount):\n",
    "        countString = countString + str(i[0]) + \" \" + str(i[1]) + \"\\n\"\n",
    "    countString = countString + \"乘客平均数量为：\" + str(float(allPassengerCount) / dataLength)\n",
    "    f.write(countString)\n",
    "\n",
    "# 一个月中细分的每一天运行次数\n",
    "dateTimeCountRDD = csvData.map(lambda lines: (datetime.datetime.strptime(lines[5].split(\" \")[0], \"%Y-%m-%d\").date(), 1))\n",
    "dateTimeCount = dateTimeCountRDD.reduceByKey(operator.add).collect()\n",
    "countString = \"日期 出租车运行次数\\n\"\n",
    "with open(\"./file/dateTimeCount.txt\", \"w\") as f:\n",
    "    for i in sorted(dateTimeCount):\n",
    "        countString = countString + str(i[0]) + \" \" + str(i[1]) + \"\\n\"\n",
    "    f.write(countString)\n",
    "\n",
    "# 一天中各个时间段出租车运行的次数\n",
    "hourTimeCountRDD = csvData.map(lambda lines: (datetime.datetime.strptime(lines[5].split(\" \")[1], \"%H:%M:%S\").hour,1))\n",
    "hourTimeCount = hourTimeCountRDD.reduceByKey(operator.add).collect()\n",
    "countString = \"时间段 出租车运行次数\\n\"\n",
    "with open(\"./file/hourTimeCount.txt\", \"w\") as f:\n",
    "    for i in sorted(hourTimeCount):\n",
    "        countString = countString + str(i[0]) + \" \" + str(i[1]) + \"\\n\"\n",
    "    f.write(countString)\n",
    "\n",
    "# 出租车运行的平均时间\n",
    "tripTimeTotal= csvData.map(lambda lines: int(lines[8])).sum()\n",
    "print(f\"出租车运行的平均时间为：{float(tripTimeTotal / dataLength)}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import math\n",
    "# 获取乘车时间的分布(按每一分钟划分）\n",
    "PartitionTime = 60\n",
    "tripTimePartitionRDD = csvData.map(lambda lines: (math.ceil(float(lines[8]) / PartitionTime) ,1))\n",
    "tripTimePartition = tripTimePartitionRDD.reduceByKey(operator.add).sortByKey().collect()\n",
    "countString = \"乘车时间范围(分钟) 车次 \\n\"\n",
    "with open(\"./file/tripTimePartition.txt\", \"w\") as f:\n",
    "    for i in sorted(tripTimePartition):\n",
    "        countString = countString + str(i[0]) + \"-\" +str(i[0] + 1) + \" \" + str(i[1]) + \"\\n\"\n",
    "    f.write(countString)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "出租车运行的平均距离为：2.770975670679651KM\n"
     ]
    }
   ],
   "source": [
    "tripDistanceTotal = csvData.map(lambda lines: float(lines[9])).sum()\n",
    "print(f\"出租车运行的平均距离为：{float(tripDistanceTotal / dataLength)}KM\")\n",
    "\n",
    "# 乘车距离分布（按每一千米划分）\n",
    "tripDistancePartitionRDD = csvData.map(lambda lines: (math.ceil(float(lines[9])), 1))\n",
    "tripDistancePartition = tripDistancePartitionRDD.reduceByKey(operator.add).sortByKey().collect()\n",
    "countString = \"乘车距离(km) 车次 \\n\"\n",
    "with open(\"./file/tripDistancePartition.txt\", \"w\") as f:\n",
    "    for i in sorted(tripDistancePartition):\n",
    "        countString = countString + str(i[0]) + \"-\" +str(i[0] + 1) + \" \" + str(i[1]) + \"\\n\"\n",
    "    f.write(countString)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kan sei\n"
     ]
    }
   ],
   "source": [
    "# 上车位置聚类\n",
    "from pyspark.mllib.linalg import Vectors\n",
    "from pyspark.mllib.clustering import KMeans\n",
    "from pyspark.mllib.clustering import GaussianMixture\n",
    "\n",
    "correctLocationData = csvData.filter(lambda line: -75 < float(line[10]) < -70 and 36 < float(line[11]) < 45 )\n",
    "pickUpLocation = correctLocationData.map(lambda lines: Vectors.dense([float(lines[10]), float(lines[11])]))\n",
    "# print(pickUpLocation.collect())\n",
    "\n",
    "# KmeansCenter = KMeans.train(pickUpLocation, k=5, maxIterations=10)\n",
    "# # GaussianMixtureCenter = GaussianMixture.train(pickUpLocation, k=3, maxIterations=10)\n",
    "# countString = \"经度 纬度 \\n\"\n",
    "# with open(\"./file/pickUpLocation.txt\", \"w\") as f:\n",
    "#     for i in KmeansCenter.clusterCenters:\n",
    "#     # for i in GaussianMixtureCenter.cluster:\n",
    "#         countString = countString +str(i[0]) + \" \" + str(i[1]) + \"\\n\"\n",
    "#         print(countString)\n",
    "#     f.write(countString)\n",
    "# # print(GaussianMixtureCenter.prediction)\n",
    "print(\"kan sei\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-5b170f1f",
   "language": "python",
   "display_name": "PyCharm (NY_taxi)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}